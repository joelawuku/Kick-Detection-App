import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import label_binarize
from sklearn.pipeline import make_pipeline

# Load the dataset
data = pd.read_csv('Openlab_wellA.csv')

# Preprocessing - Normalizing the dataset
scaler = StandardScaler()
X = scaler.fit_transform(data.drop(columns=['Class']))
y = data['Class']

# Binarize the output
y = label_binarize(y, classes=[0, 1])

# Define machine learning models
models = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'SVM': make_pipeline(StandardScaler(), SVC(probability=True)),  # SVM needs probability=True for ROC curve
    'KNN': KNeighborsClassifier(),
    'Neural Network': MLPClassifier(max_iter=1000)
}

# Perform 10-fold cross-validation for each model
kf = KFold(n_splits=10, shuffle=True, random_state=42)

for model_name, model in models.items():
    tprs = []
    aucs = []
    mean_fpr = np.linspace(0, 1, 100)

    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        model.fit(X_train, y_train.ravel())
        y_pred_proba = model.predict_proba(X_test)[:, 1]

        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        tprs.append(np.interp(mean_fpr, fpr, tpr))
        tprs[-1][0] = 0.0
        aucs.append(roc_auc)

    mean_tpr = np.mean(tprs, axis=0)
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)
    std_auc = np.std(aucs)

    plt.figure(figsize=(8, 8))
    plt.plot(mean_fpr, mean_tpr, color='red', lw=2, label=f'Mean ROC (AUC = {mean_auc:.2f} Â± {std_auc:.2f})')
    plt.fill_between(mean_fpr, mean_tpr - np.std(tprs, axis=0), mean_tpr + np.std(tprs, axis=0), color='grey', alpha=0.2)
    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='black', alpha=0.8)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate', fontsize=14)
    plt.ylabel('True Positive Rate', fontsize=14)
    plt.title(f'ROC Curve for {model_name}-PSO', fontsize=16)
    plt.legend(loc="lower right", fontsize=12)
    plt.show()
